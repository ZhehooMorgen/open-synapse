# 人工智能应当是一个基于启发式搜索的NP问题求解器

在[Readme](../../README.md)中，我们已经指出，当前AI技术落地的两大问题是：

1. 缸中之脑问题
2. 模型能力问题

其中缸中之脑的问题已经在Readme中有了比较详细的讨论，而模型能力问题我们在Readme中只是简单提了一下，认为这是一个需要全新思路才能解决的问题。

模型能力的问题，其实也就是输出质量的问题，我们可以细分为好几个问题：

1. 模型会有幻觉，无法区分内容可靠性。
2. 模型无法进行复杂的推理和规划。
3. 模型的上下文窗口有限，无法记住长期记忆。
4. 模型可能会被prompt injection攻击，导致严重的安全漏洞。
5. 模型的内部的工作机制是一个黑盒，我们无法完全理解它的工作原理和机制，这也导致我们无法完全信任它的输出。
6. 还存在非常多的其他问题，问题太多了，我们无法在此完全列举。

这篇文档将会通过分析AI模型的本质，从本质出发来解决模型能力的问题。首先我们从经典的NP问题说起，指出AI模型的本质就是一个启发式状态空间NP问题求解器。接着，基于这个理论，我们可以分析出当前AI模型和工具在训练和使用AI模型时存在的缺陷，并且我们可以基于这个理论来设计出一个全新的AI模型和工具的架构，这个架构可以在很大程度上解决当前AI模型能力不足的问题。

本文档为了叙述的方便性和清晰性，一定程度上牺牲了数学上的严谨性，来更直观的表达这个理论和相关的设计。严谨的学术性论文的写作和发表是我们未来的工作计划。

## AI模型是一个启发式状态空间NP问题求解器

### 从一个现象说起

当我们要求LLM完成一项高难度的分析任务时，直接提问的效果往往令人失望。但如果在prompt中加入一步引导——例如，要求模型先问自己"应该用什么思路来分析这个问题"——输出质量往往会有显著提升。

这个现象背后隐藏着一个关键问题：既然模型在引导下能给出更好的答案，那么这种更优解法的能力，原本就存在于模型之中。为什么模型一开始不这么做？

要回答这个问题，我们先需要理解AI模型在做什么。

### 搜索即生成

在计算复杂性理论中，P问题是指可以在多项式时间内求解的问题，而NP问题是指可以在多项式时间内**验证**一个给定解是否正确的问题。需要说明的是，本文对P和NP的使用是非正式的类比，与严格的数学定义存在出入：严格意义上的P和NP是针对判定问题（decision problem）的复杂性类，且P⊆NP已被证明成立，而P≠NP至今仍是未解的猜想。本文借用这一框架作为直觉性的描述工具，而非严谨的数学论断。两类问题的本质区别在于：找到解与核验解，往往难度相差悬殊。面对NP问题，计算机科学给出的实用方案是**启发式搜索**——不追求全局最优解，而是通过某种启发函数引导搜索方向，在可接受的时间内找到足够好的解。

LLM的生成过程正是如此。当模型回答一个问题时，它并不是从某个知识库中"查找"答案，而是在一个近乎无穷的token序列空间中，依据训练习得的概率分布，逐步采样出一段文字。这个过程的本质，是在巨大的状态空间中推进的搜索——每一个token的生成，都是从当前状态出发、向下一个状态的转移。

**LLM就是一个启发式状态空间NP问题求解器。** 它的"启发函数"由训练数据和权重参数编码，它的"搜索策略"由自回归生成机制决定。

### 为什么Prompt技巧有效

回到最初的问题：为什么引导性prompt能显著提升输出质量？

因为prompt改变了搜索路径。自回归生成本质上是贪心解码——模型在当前状态下选择概率最高的下一步，而不是从全局评估哪条路径最终会抵达最优解。引导性prompt相当于为搜索器提前注入了启发信息，使搜索过程经过更有价值的中间状态，从而更大概率地抵达高质量的输出区域。

Chain-of-Thought、self-questioning、think-step-by-step……这些技术在形式上各有不同，但本质相同：它们都是在调整搜索路径。模型并非因为"被引导"才变得"更聪明"，而是因为更好的搜索路径，激活了参数空间中本已潜在的求解能力。

### 灵感作为搜索策略

这个框架同样可以解释人类思维中更难以言说的现象。

所谓灵感，可以理解为：通过反思已经探索过的搜索空间，大胆推断在未探索的某个区域可能存在质量更高的解，从而将搜索器引向那个方向进行尝试。它不是凭空出现的，而是已有搜索经验的归纳与外推。人类的思考，从试探、观察到总结，本质上就是在无穷搜索空间中，尽力迈向最优解的过程。

P≠NP这一猜想，是理解上述一切现象的根本背景：不存在一个可以高效解决所有NP问题的通用算法。无论是人脑还是LLM，都是在这个约束下工作的启发式搜索器。

### 人类使用AI的本质

如果说LLM是一个NP求解器，那么人类使用AI这件事的逻辑就变得非常清晰：把问题交给AI，是把NP的生成负担转嫁给机器；而人类自己只需评估生成的解是否可接受。验证一个解是否合格，通常远比从头生成一个解容易——这更接近于P类问题。

因此，使用AI的根本目的，是将不确定性问题中生成解的负担外包，而自己承担相对轻松的验证工作。

## 当前AI模型作为启发式状态空间NP问题求解器时的固有缺陷

现有的LLM工具，无论是直接调用还是封装成agent，其核心流程几乎都是"一次生成，直接输出"。模型依据当前上下文生成概率最高的token序列，然后将其作为最终答案返回——这个过程中不存在任何显式的验证步骤，也不存在对候选解的评估和进一步优化。

换言之，搜索和输出是同一个动作。模型在搜索空间中走出的第一条路径，就成了交付给用户的答案。这是一个根本性的设计缺位。

## 基于启发式状态空间NP问题求解器理论的AI模型和工具设计

### 设计约束

在设计之前，有必要先明确这个系统需要应对的结构性约束。这两个约束并非AI所特有，在任何形式的协作外包中都可以观察到——外包公司长期存在的"验收困难"和"交付延迟、质量低下"，在人机协作中以同样的面貌出现，根源也完全相同：

**验证复杂度**

将生成工作外包之后，验证工作留在了委托方手中。然而在某些领域，验证一个解是否正确本身就是高度复杂的任务。一旦验证本身升级为NP级别的工作，整个"外包生成、自留验证"的效率提升逻辑就会断裂。

**搜索空间的控制**

搜索空间要么过小——求解器始终在狭窄区域内打转，无法触及高质量解所在的区域；要么过大——搜索发散，无法在可接受的时间内收敛到任何可行解。如何引导搜索方向、如何控制搜索范围，是任何求解器设计都必须正面回答的问题。

### 设计目标

基于以上约束，我们对这个求解器的成功有了明确的度量标准：**在给定的上下文资源约束下，尽可能向正确方向进行最大范围的搜索，以返回最佳结果。**

单次LLM调用是一次搜索尝试，而整个系统应当是一个可以持续迭代、自我修正的搜索引擎。为了实现这一点，我们通过编排器将LLM的不同能力分工为五个专职角色。

### 角色设计

**启发器（Heuristic）**

负责分析当前的问题和搜索状态，判断哪些方向最有可能存在优质解。这对应人类思维中的元认知——先问自己"应该怎么思考这个问题"，再开始思考。

启发器不应只给出单一方向，而应同时提出多个可能的思路。不同思路代表搜索空间中的不同分支，后续可由编排器并发展开，充分利用计算资源，避免因过早收窄方向而错失更优解。

**搜索器（Searcher）**

在启发器提供的方向引导下生成候选解。在新架构中，它不再是无方向的单次生成，而是在指定方向上的定向探索。

当搜索器发现当前方向过于模糊或分支过多时，可以递归地调用启发器，对该子方向进一步细化，再继续推进。这种机制自然地形成多级树状搜索结构：每个节点可以展开为新的子方向，搜索深度和广度都可以根据资源约束动态调整。

**细化器（Refiner）**

对候选解进行迭代细化和修正。搜索器产出的可能是一个粗糙但方向正确的候选解，细化器负责将其逐步打磨为质量更高、更完整的解。这个过程可以多轮进行。

**评估器（Evaluator）**

对候选解进行多维度评估，为后续的决策提供依据。评估维度至少应包括：

1. **解的复杂度**：过于复杂的解可能是过拟合，并且会导致验证本身变成NP问题，直接破坏"人负责验证"的效率假设。好的解应当在满足需求的前提下尽可能简洁。
2. **可解释性**：解的推理链是否清晰，人类是否能够理解和追溯其得出过程。
3. **依据的可考察性**：解中涉及的知识点、引用的事实和数据，是否具备可验证的来源。
4. **其他约束**：根据应用场景，可扩展加入版权合规性、内容安全性等维度的检查。

需要注意的是，以上的评估动作，并非真的用某个算法来进行实际的评估，而是利用例如AI模型等算法进行启发式验证。可以发现，我们故意避开了正确性维度的评估，而是看简洁性，可解释性等指标。因为我们知道，答案的评估本身可能就是一个NP问题，如果评估器试图给出一个绝对的判断，那么它自己就会陷入效率危机，无法胜任"验证"的角色。所以评估器更多是看这个解“长得好不好看”。

评估器的输出是结构化的评分与分析，而不仅仅是一个通过/不通过的判断。这些信息将交由决策与整合器处理。

**决策与整合器（Decision & Integrator）**

在多个并发搜索分支产生各自的候选解后，负责综合评估结果做出最终决策。其工作包含三种情形：

- **择优返回**：若某个分支的候选解在各维度评估中显著优于其他分支，直接选取该解输出。
- **整合多解**：若多个分支均产生了有价值的结论且相互补充，将其合并为一个更完整的答案。
- **启动下一轮搜索**：若当前所有分支的结果均不令人满意，对本轮搜索中获得的有效信息进行总结，提炼出"哪些方向已被排除"、"哪些发现值得深入"等结构化洞察，作为下一轮启发器的输入，以新的策略重新展开搜索。

这使得整个系统不只是单次搜索，而是一个可以从失败中学习、持续迭代的搜索循环。

### MVP策略

在MVP阶段，以上所有角色均可由现成的通用LLM（如DeepSeek）扮演，通过精心设计的prompt和编排逻辑来实现分工协作。这意味着无需等待专用模型的训练和部署，现有工具即可验证这套架构的可行性。

为每个角色专门训练和微调独立的模型，是后续优化的方向，而非当前阶段的必要条件。

## 为什么这个设计可以解决当前AI模型能力不足的问题

引言中列出了模型能力不足的若干具体表现。在NP求解器的架构下，这些问题的性质发生了根本性的转变。

**幻觉问题**

在传统的单次生成中，幻觉是悄无声息地混入最终输出的错误，用户无从感知。在新架构中，候选解首先由评估器审查，幻觉从"无法感知的输出错误"转变为"系统内部可处理的搜索噪声"。它不会消失，但其影响范围被限制在系统内部，不再直接暴露给用户。

**复杂推理和规划问题**

复杂任务之所以难以一次性完成，是因为需要经过的中间步骤太多，单次贪心解码很容易走偏。启发器提供方向、搜索器定向生成、细化器迭代修正的多步机制，将复杂推理分解为一系列有方向的短程搜索，从结构上缓解了这个问题。

**不可解释性问题**

编排式工作流天然留下了中间记录：启发器的分析推断、搜索器的候选解、评估器的判断依据。这使得模型的推理过程具备了一定程度的可追溯性，从而部分缓解了"黑盒"问题。

**关于幻觉、道德性与失控AI**

将AI定位为NP求解器，从根本上重塑了我们对这些问题的理解。P≠NP保证了不存在可以高效解决所有NP问题的通用算法，这意味着AI永远是一个受约束的搜索引擎，而非一个逼近全能的通用智能体。

在这个框架下，所谓"失控的强人工智能"所依赖的前提——AI能够自主地在任意领域找到任意问题的最优解——在理论上就是不成立的。一个被明确设计为"在约束下搜索解"的系统，其行为边界比一个试图模拟通用智能的系统要清晰得多，也可信得多。

## 总结

本文从P/NP问题出发，揭示了AI语言模型的本质：**一个启发式状态空间NP问题求解器**。

基于这个定位，我们可以清晰地理解：prompt技巧之所以有效，是因为它改变了搜索路径；人类使用AI之所以能提升生产力，是因为它将NP的生成负担外包，人类只需承担相对轻松的验证工作。

现有AI工具的核心缺陷在于搜索和输出是同一个动作——没有显式的验证与优化环节。而任何NP求解器都必须面对两个结构性约束：验证复杂度和搜索空间的控制。

为此，我们提出了一种基于编排器的五角色架构：启发器并发提出多条思路、搜索器在各分支定向推进并可递归细化为树状结构、细化器对候选解迭代打磨、评估器从复杂度/可解释性/依据可考察性等多维度把关、决策与整合器综合各分支结果择优输出或驱动下一轮搜索。这套架构将NP求解的各个环节显式化、可控化，使整个系统成为一个可以从失败中学习的持续迭代搜索循环。

人类在知道自己无法成为神之后，才真正开始建设属于自己的文明。人类在知道AI无法成为神之后，才真正用其建造通向未来的阶梯。
